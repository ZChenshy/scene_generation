name: "gaussiandroom-sdxl"
tag: "${rmspace:${system.prompt_processor.prompt},_}"
exp_root_dir: "outputs"
seed: 0
 
data_type: "random-outward-camera-datamodule" # 对应threeStudio/data/uncond_out.py

data:
  batch_size: 1
  height: 1024 
  width: 1024 

  light_sample_strategy: "dreamfusion"

  fix: True #决定是否固定训练相机位置
  fix_fovy_deg: 60 #相机视角固定不变
  
  #################################################################################################
  #  本部分决定相机的生成。elevation将相机位置固定在场景正上方。camera_distance决定了相机的高度     #
  #  修改相机的仰角,在uncond_out.py中RandomCameraIterableDatasetCustom 的collate 部分              #
  #################################################################################################
  fix_elevation_deg: 90 #角度制
  fix_azimuth_deg: 80 #角度制,这里暂时未使用
  fix_camera_distance: 0.25 

  ####

  n_val_views: 1
  eval_elevation_deg: 45
  eval_camera_distance: 0.8
  eval_fovy_deg: 60

system_type: "gaussianRoom-system"
system:

  geometry_type: "gaussian-splatting"
  geometry:
    max_num: 1000000 #8000000 # 500000 is original, max number of points
    position_lr: [0, 0.00005, 0.000025, 1500] # [0, 0.001, 0.00002, 1000] [start_step, start_value, end_value, end_step] will multiply by 10 at create_from_pcd
    scale_lr: 0.005    # 0.005
    feature_lr: 0.005  # 0.01
    opacity_lr: 0.011  # 0.05
    rotation_lr: 0.001 # 0.005
    densification_interval: 100 #300
    prune_interval: 100
    opacity_reset_interval: 50000000
    densify_from_iter: 500
    densify_until_iter: ${trainer.max_steps}
    prune_from_iter: 500
    prune_until_iter: ${trainer.max_steps}
    densify_grad_threshold: 0.0002 #0.01 #original gaussian splatting is 0.0002
    min_opac_prune: 0.005
    split_thresh: 0.02
    opacity_init: 1.0

    prune_big_points: false # default: false #! 设置为True后，地板会变黑？
    radii2d_thresh: 1000 #1000

    geometry_convert_from: "coarse_room/scene_pcd_whole_wall.ply" #TODO: Auto connect to scene pcd 
    load_ply_only_vertex: True #! 仅加载点云中的点位置，颜色随机初始化


  renderer_type: "diff-gaussian-rasterizer-advanced"
  renderer:
    debug: false
    invert_bg_prob: 0.5 # TODO：确定背景颜色

  material_type: "no-material" # unused
  material:
    n_output_dims: 0


  background_type: "solid-color-background" # unused


  prompt_processor_type: "stable-diffusion-xl-prompt-processor" 
  prompt_processor:
    pretrained_model_name_or_path: "/remote-home/hzp/Models/stabilityai/stable-diffusion-xl-base-1.0"
    prompt: ???
    negative_prompt: "unrealistic, over-saturated, Animation style, outdoor view"


  guidance_type: "stable-diffusion-xl-depth-controlnet-guidance-image" 
  guidance:
    pretrained_model_name_or_path: "/remote-home/hzp/Models/stabilityai/stable-diffusion-xl-base-1.0" 
    controlnet_name_or_path: "/remote-home/hzp/Models/diffusers/controlnet-depth-sdxl-1.0" 
    half_precision_weights: false
    conditioning_scale: 0.55 # Depth conditioning_scale
    random_seed: 978364352 # random seed to generate the image
    num_inference_steps: 30 # stable diffusion inference step num

  exporter_type: "gaussian-mesh-exporter"

  loggers:
    wandb:
      enable: false
      project: 'threestudio'
      name: None

  loss:
    lambda_l1: 0.8 #0.1
    lambda_ssim: 0.2
    
    lambda_position: 0.0001 # 1.0
    lambda_opacity: 0.1
    lambda_scales: 0.001
    lambda_tv_loss: 1.0
    lambda_depth_tv_loss: 0.5 # original 1.0


trainer:
  max_steps: 2000
  log_every_n_steps: 1
  num_sanity_val_steps: 0
  val_check_interval: 100
  enable_progress_bar: true
  precision: 32-true

checkpoint:
  save_last: true # save at each validation time
  save_top_k: -1
  every_n_train_steps: ${trainer.max_steps}
