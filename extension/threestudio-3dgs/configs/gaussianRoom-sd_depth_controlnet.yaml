name: "gaussiandroom-sd"
tag: "${rmspace:${system.prompt_processor.prompt},_}"
exp_root_dir: "outputs"
seed: 0
 
data_type: "random-outward-camera-datamodule" # 对应threeStudio/data/uncond_out.py

data:
  batch_size: 1
  height: 512
  width: 512

  light_sample_strategy: "dreamfusion"

  fix: True #决定是否固定训练相机位置
  fix_fovy_deg: 60 #相机视角固定不变
  
  #################################################################################################
  #  本部分决定相机的生成。elevation将相机位置固定在场景正上方。camera_distance决定了相机的高度     #
  #  修改相机的仰角,在uncond_out.py中RandomCameraIterableDatasetCustom 的collate 部分              #
  #################################################################################################
  fix_elevation_deg: 90 #角度制
  fix_azimuth_deg: 80 #角度制,这里暂时未使用
  fix_camera_distance: 0.10

  ####

  n_val_views: 1
  eval_elevation_deg: 45
  eval_camera_distance: 0.8
  eval_fovy_deg: 60

system_type: "gaussianRoom-system"
system:

  geometry_type: "gaussian-splatting"
  geometry:
    max_num: 8000000
    position_lr: [0, 0.00005, 0.000025, 1000]
    scale_lr: 0.005
    feature_lr: 0.01
    opacity_lr: 0.05
    rotation_lr: 0.001
    densification_interval: 100
    prune_interval: 100
    opacity_reset_interval: 50000000
    densify_from_iter: 500
    densify_until_iter: ${trainer.max_steps}
    prune_from_iter: 500
    prune_until_iter: ${trainer.max_steps}
    densify_grad_threshold: 0.01
    min_opac_prune: 0.005
    split_thresh: 0.02
    radii2d_thresh: 1000

    geometry_convert_from: "/remote-home/share/room_gen/roomPCD/4944051f-3a7e-4387-b5f3-f925ae6da57e/LivingRoom-4719/scene_pcd_whole_wall.ply" #TODO: Auto connect to scene pcd 
    load_ply_only_vertex: True #! 仅加载点云中的点位置


  renderer_type: "diff-gaussian-rasterizer-advanced"
  renderer:
    debug: false
    invert_bg_prob: 0.5 # TODO：确定背景颜色

  material_type: "no-material" # unused
  material:
    n_output_dims: 0

  background_type: "solid-color-background" # unused


  prompt_processor_type: "stable-diffusion-prompt-processor"
  prompt_processor:
    pretrained_model_name_or_path: "/remote-home/share/Models/runwayml/stable-diffusion-v1-5"
    prompt: ???
    negative_prompt: "unrealistic, over-saturated, Animation style"


  guidance_type: "depth-controlnet-SD1.5-guidance"
  guidance:
    pretrained_model_name_or_path: "/remote-home/share/Models/runwayml/stable-diffusion-v1-5" 
    controlnet_name_or_path: "/remote-home/share/Models/lllyasviel/control_v11f1p_sd15_depth" 
    ddim_scheduler_name_or_path: "/remote-home/share/Models/runwayml/stable-diffusion-v1-5" 
    half_precision_weights: false
    guidance_scale: 100 # 7.5 for csd
    condition_scale: 0.75 # Depth conditioning_scale
    weighting_strategy: sds
    min_step_percent: 0.02
    max_step_percent: 0.98
    grad_clip: [0, 1.5, 2.0, 1000]

  exporter_type: "gaussian-mesh-exporter"

  loggers:
    wandb:
      enable: false
      project: 'threestudio'
      name: None

  loss:
    lambda_sds: 1.0
    lambda_position: 0.0001
    lambda_opacity: 0.1
    lambda_scales: 0.001
    lambda_tv_loss: 1.0
    lambda_depth_tv_loss: 0.0 # original 1.0


trainer:
  max_steps: 2000 
  log_every_n_steps: 1
  num_sanity_val_steps: 0
  val_check_interval: 100
  enable_progress_bar: true
  precision: 32-true

checkpoint:
  save_last: true # save at each validation time
  save_top_k: -1
  every_n_train_steps: ${trainer.max_steps}
